#!/usr/bin/perl -w

use strict;
use diagnostics;
 
use LWP::UserAgent;
use Getopt::Std;
use Time::Local;
use POSIX qw(strtod);

use Getopt::Std;

use vars qw ($USAGE $VERSION $BASENAME);
use vars qw ($opt_V $opt_h $opt_H $opt_w $opt_c $opt_o $opt_T $opt_t $opt_A $opt_D);
use vars qw ($warn_thresh $crit_thresh);
use vars qw (@warn_thresholds @crit_thresholds);
use subs qw (getnum basename2 nagios_unknown nagios_critical nagios_warning nagios_ok);

$VERSION="1.0.0 28-Sep-2008";
$BASENAME=basename2($0);

$USAGE = <<EOUSAGE;
Usage: $0 -H host -w X -c Y -oN -T type

  where
    -H host gives host to check for host-y stuff
    -w X gives a threshold of X for a nagios WARNING (yellow)
    -c Y gives a threshold of Y for a nagios CRITICAL (red)
    -o N gives the host resource to check and is defined as:
            1: disk
            2: aca-cluster
            3: rrd-processes
            4: 409-percentages-for-3it
            5: load avg
            6: swap space
            666: aca cpu
            667: aca ses
            668: aca tps
           2112: tps < 1.0 && cpu > 25%
           u812: stuck core check (TPS / CPU linear regression)
    -T TYPE if -o2, then TYPE is the aca-cluster resource-type to check:
        codes: rsp codes
        times: latency times
    -A AVERAGE if -ou812, then AVERAGE is which EWMA running average
        to use for TPS and CPU
          0: instantaneous (default)
          1: 1-min ewma
          5: 5-min ewma
         15: 15-min ewma
    -D DATAPLOT_WINDOW  if -ou812, then DATAPLOT_WINDOW is the size of
        the sample window (in minutes) to use. Default is 30 minutes. This
        should be (roughly) equal to the check interval for this plugin,
        although making it slightly larger is ok too.

  diskspace example:
      $0 -H 172.22.0.66 -w 85 -c 90 -o1
  aca-cluster example:
      $0 -H 172.17.0.37 -o2 -T codes
  stuck core check example:
      $0 -H 172.18.0.102 -ou812 -w 15 -c 30

  returns:
      nagios-formatted string.

  NOTE: o2 (aca-cluster) does not have thresholds -- it will either return
   OK (if last RRD reading on HOST for TYPE was good) or CRITICAL (if last
   reading was bad). This is because debouncing has already been done by the
   RRD predictive algorithms on the remote host, and the error state should
   almost certainly be monitored, if not acted upon.

EOUSAGE

my ($nag_status, $perf_data);

sub getnum {
    use POSIX qw(strtod);
    my $str = shift;
    $str =~ s/^\s+//;
    $str =~ s/\s+$//;
    $! = 0;
    my($num, $unparsed) = strtod($str);
    if (($str eq '') || ($unparsed != 0) || $!) {
        return;
    } else {
        return $num;
    }
}

sub basename2 {
    my $fullname = shift;
    return ( $fullname =~ m{^.*\/([^/]+)}xms ? $1 : $fullname );
}

###########################################################
# helpers for returning plugin results to nagios
###########################################################
sub nagios_unknown {
    my ($subfun, $errmsg) = @_;
    print STDOUT "$subfun UNKNOWN: ", $errmsg, "\n";
    exit 3;
}
                                                                                                                                                                                   
sub nagios_critical {
    my ($subfun, $errmsg, $perfdata) = @_;
    if (defined($perfdata) && (! "" eq $perfdata)) {
        print STDOUT "$subfun CRITICAL: ", $errmsg, "| ", $perfdata, "\n";
    } else {
        print STDOUT "$subfun CRITICAL: ", $errmsg, "\n";
    }
    exit 2;
}
                                                                                                                                                                                   
sub nagios_warning {
    my ($subfun, $errmsg, $perfdata) = @_;
    if (defined($perfdata) && (! "" eq $perfdata)) {
        print STDOUT "$subfun WARNING: ", $errmsg, "| ", $perfdata, "\n";
    } else {
        print STDOUT "$subfun WARNING: ", $errmsg, "\n";
    }
    exit 1;
}
                                                                                                                                                                                   
sub nagios_ok {
    my ($subfun, $ok_msg, $perfdata) = @_;
    if (defined($perfdata) && (! "" eq $perfdata)) {
        print STDOUT "$subfun OK: ", $ok_msg, "| ", $perfdata, "\n";
    } else {
        print STDOUT "$subfun OK: ", $ok_msg, "\n";
    }
    exit 0;
}

sub nagios_unknown_terse {
  my $msg = shift;
  $msg = "Unknown Error" unless defined($msg);
  print STDOUT "UNKNOWN - ", $msg, "\n";
  exit 3;
}

sub nagios_critical_terse {
  my ($msg, $perfdata) = @_;
  nagios_unknown_terse("Internal Error") unless defined($msg);
  $perfdata = "" unless defined($perfdata);
  print STDOUT "CRITICAL - ", $msg, "|", $perfdata, "\n";
  exit 2;
}

sub nagios_warning_terse {
  my ($msg, $perfdata) = @_;
  nagios_unknown_terse("Internal Error") unless defined($msg);
  $perfdata = "" unless defined($perfdata);
  print STDOUT "WARNING - ", $msg, "|", $perfdata, "\n";
  exit 1;
}

sub nagios_ok_terse {
  my ($msg, $perfdata) = @_;
  nagios_unknown_terse("Internal Error") unless defined($msg);
  if (defined($perfdata)) {
    $perfdata = "|" . $perfdata;
  } else {
    $perfdata = "";
  }
  print STDOUT "OK - ", $msg, $perfdata, "\n";
  exit 0;
}

###########################################################
# execute remote cmd via ssh
###########################################################
sub check_via_novarra_ssh {
    my ($remote_cmd, $hostname) = @_;
    $hostname = "novarra\@$hostname";
    my $ssh_cmd = qq{ ssh -n -x -T -i /home/nagios/.ssh/novarra_id_rsa_SLAVE_ACAs $hostname "${remote_cmd}" };
    my $str=`${ssh_cmd}`;
    if ($?) {
        nagios_unknown_terse("bad exit from ssh to [$hostname]: [$?]");
    }
    return $str;
}

###########################################################
# execute remote cmd via ssh
###########################################################
sub check_via_nagios_ssh {
    my ($remote_cmd, $hostname) = @_;
    $hostname = "nagios\@$hostname";
    #### my $ssh_cmd = qq{ ssh -n -x -T -i /home/nagios/.ssh/id_rsa $hostname "${remote_cmd}" };
    my $ssh_cmd = qq{ ssh -n -x -T $hostname "${remote_cmd}" };
    my $str=`${ssh_cmd}`;
    if ($?) {
        nagios_unknown_terse("bad exit from ssh to [$hostname]: [$?]");
    }
    return $str;
}

sub apla($$$$) {
    my $aca    = shift;
    my $stat   = shift;
    my $lambda = shift;
    my $N      = shift;
    if (("ALL" eq $stat) && ("ALL" eq $lambda)) {
      die "Cannot do ALL x ALL!";
    }
    die "Bad stat:[$stat]" unless (
                  ($stat eq "cpu")
               || ($stat eq "ses")
               || ($stat eq "tps"));
    die "Bad lambda:[$lambda]" unless (
                  ($lambda eq "ALL")
               || ($lambda eq "lo")
               || ($lambda eq "mid")
               || ($lambda eq "hi"));
    die "Bad N:[$N]" unless (($N >= 1) && ($N <= 10));
    use vars qw( $prev_ts $current_ts );
    use vars qw( $hundred_k_503 $step $output );
    $output = check_via_nagios_ssh( "tail -${N} /var/log/novarra/aca-perf-load-averager.log", $aca );
    my $num_warn = 0;
    my $num_crit = 0;
    my @crits;
    my @warns;
LOG_LINE:
    # we loop thru up to $N lines, bailing after the first one with valid data.
    foreach my $line ( split '\n', $output ) {
      my ($tstamp,
          $cpu_0,$cpu_1,$cpu_5,$cpu_15,
          $ses_0,$ses_1,$ses_5,$ses_15,
          $tps_0,$tps_1,$tps_5,$tps_15 )
        = split '\s+', $line;
        my ($load_0,$load_1,$load_5,$load_15);
        if ($stat eq "cpu") {
          ($load_0,$load_1,$load_5,$load_15) = ($cpu_0,$cpu_1,$cpu_5,$cpu_15);
        }
        if ($stat eq "ses") {
          ($load_0,$load_1,$load_5,$load_15) = ($ses_0,$ses_1,$ses_5,$ses_15);
        }
        if ($stat eq "tps") {
          ($load_0,$load_1,$load_5,$load_15) = ($tps_0,$tps_1,$tps_5,$tps_15);
        }
        my $lhs = sprintf("apla-${stat} load average: %1.2f, %1.2f, %1.2f, %1.2f",$load_0,$load_1,$load_5,$load_15);
        my $perfdata = sprintf("load0=%1.3f;%1.3f;%1.3f;0; load1=%1.3f;%1.3f;%1.3f;0; load5=%1.3f;%1.3f;%1.3f;0; load15=%1.3f;%1.3f;%1.3f;0;",
                          $load_0,$warn_thresholds[0],$crit_thresholds[0],
                          $load_1,$warn_thresholds[1],$crit_thresholds[1],
                          $load_5,$warn_thresholds[2],$crit_thresholds[2],
                          $load_15,$warn_thresholds[3],$crit_thresholds[3] );
        my $output = $lhs . "|" . $perfdata;
        if ($load_0 >=  $crit_thresholds[0]) { nagios_critical_terse($lhs,$perfdata); }
        if ($load_1 >=  $crit_thresholds[1]) { nagios_critical_terse($lhs,$perfdata); }
        if ($load_5 >=  $crit_thresholds[2]) { nagios_critical_terse($lhs,$perfdata); }
        if ($load_15 >=  $crit_thresholds[3]) { nagios_critical_terse($lhs,$perfdata); }
        if ($load_0 >=  $warn_thresholds[0]) { nagios_warning_terse($lhs,$perfdata); }
        if ($load_1 >=  $warn_thresholds[1]) { nagios_warning_terse($lhs,$perfdata); }
        if ($load_5 >=  $warn_thresholds[2]) { nagios_warning_terse($lhs,$perfdata); }
        if ($load_15 >=  $warn_thresholds[3]) { nagios_warning_terse($lhs,$perfdata); }
        nagios_ok_terse($lhs,$perfdata);
####        nagios_ok_terse($lhs);
    }
    nagios_unknown("apla", "Unimplemented");
}

sub apla_tps_lo_cpu_hi($$$$) {
    my $aca    = shift;
    my $stat   = shift;
    my $lambda = shift;
    my $N      = shift;
    if (("ALL" eq $stat) && ("ALL" eq $lambda)) {
      die "Cannot do ALL x ALL!";
    }
    die "Bad stat:[$stat]" unless (
                  ($stat eq "cpu")
               || ($stat eq "ses")
               || ($stat eq "tps"));
    die "Bad lambda:[$lambda]" unless (
                  ($lambda eq "ALL")
               || ($lambda eq "lo")
               || ($lambda eq "mid")
               || ($lambda eq "hi"));
    die "Bad N:[$N]" unless (($N >= 1) && ($N <= 10));
    use vars qw( $prev_ts $current_ts );
    use vars qw( $hundred_k_503 $step $output );
    $output = check_via_nagios_ssh( "tail -${N} /var/log/novarra/aca-perf-load-averager.log", $aca );
    my $num_warn = 0;
    my $num_crit = 0;
    my @crits;
    my @warns;
LOG_LINE:
    # we loop thru up to $N lines, bailing after the first one with valid data.
    foreach my $line ( split '\n', $output ) {
      my ($tstamp,
          $cpu_0,$cpu_1,$cpu_5,$cpu_15,
          $ses_0,$ses_1,$ses_5,$ses_15,
          $tps_0,$tps_1,$tps_5,$tps_15 )
        = split '\s+', $line;
        if (($tps_15 < 1) && ($cpu_15 >= 25)) {
          nagios_critical("apla_tps_lo_cpu_hi", "TPS_15=[${tps_15}]; CPU_15_pct=[${cpu_15}]");
        }
        nagios_ok("apla_tps_lo_cpu_hi", "TPS_15=[${tps_15}]; CPU_15_pct=[${cpu_15}]");
    }
    nagios_unknown("apla", "Unimplemented");
}

###########################################################
# check RRD HW FAILURES data table on remote host, exit with
# correct nagios output on STDOUT and with correct error code
#  @param $hostname
#  @exit with single-line string of results to STDOUT, e.g.:
#    EXAMPLE GOES HERE
#  Standard format is at
#    http://nagiosplug.sourceforge.net/developer-guidelines.html#PLUGOUTPUT
###########################################################
sub check_rrd_hw_failures($$) {
    my $host = shift;
    my $type = shift;
    use vars qw( $prev_state $prev_ts $current_state $current_ts );
    use vars qw( $last_state $num_consecutive $step $output $rrd_file );
    if ($type ne "codes" && $type ne "times") {
        die "Bad type, must be 'codes' or 'times': $type";
    }
    # get current state from remote $host.  We just tail the file
    #  and get the latest state. Format of each line of a codes FAILURES
    #  rrd file is:
    #    timestamp u-200-failue u-other-failure
    #  Eg:
    #    1196706540: 0.0000000000e+00 0.0000000000e+00
    #  , where 'u-200-failure' and 'u-other-failure' are simply 0 (no
    #  failure) or 1 (yes failure).
    #
    #  Similarly, the times FAILURES schema is:
    #    tstamp u-overall-time-failure u-preload-time-failure u-io-time-failure
    #
    #  As coded here, we are alarming based on the first boolean column
    #   (u-200-failure, or u-overall-time-failure), based on the input $type
    #   of 'codes' or 'times', respectively.

#swhitney: stupid hack for bad RRD filename on TATA (.37).
# Will remove this once the 1-week RRDs have built up
# (which will be by Monday 10 Dec 2007)
if ("172.17.0.37" eq $host && "times" eq $type) {
 $rrd_file = "/home/novarra/bin/rrd/u/u-2.0-times.rrd";
} else {
 $rrd_file = "/home/novarra/bin/rrd/u/u-hw-1day-${type}.rrd";
}
#end hack

    $output = check_via_nagios_ssh( "rrdtool fetch ${rrd_file} FAILURES | tail -10", $host );
    $num_consecutive = 0;
RRD_LINE:
    foreach my $junk ( split '\n', $output ) {
        if ( $junk =~ m{^(\d+):.(\d)\..+$}xms ) {
          $current_ts    = $1;
          $current_state = $2;
          if ( defined $prev_ts ) {
            $step = $current_ts - $prev_ts;
          }
          next RRD_LINE
              unless (defined($current_state) && defined($prev_state));
          $num_consecutive = ($prev_state eq $current_state) ? $num_consecutive + 1 : 1;
          $prev_ts    = $current_ts;
          $prev_state = $current_state;
        }
    }
    if ( ! defined($current_ts) || ! defined($current_state) ) {
        die "Can't find rrd data of type [$type] from host [$host]\n";
    }
    my $datestr = localtime($current_ts);
    if ( "0" eq $current_state ) {
        nagios_ok ("aca-cluster", "${host};${type};${datestr}","");
        return;
    }
    nagios_critical ("aca-cluster", "${host};${type};${datestr}","");
    return;
}

sub check_409_monitor_on_3it() {
    use vars qw( $prev_ts $current_ts );
    use vars qw( $hundred_k_409 $step $output );
    my $three_it_oamp_host = "172.17.0.60";
    #
    # tail the remote 409-watcher.log file.  Verify that it appears to be running
    # every 13-16s or so.  Get the # 409s per 100,000 #  rspcodes
    $output = check_via_nagios_ssh( "tail -5 /var/log/novarra/409-watcher.log", $three_it_oamp_host );
    my $num_hundred_k_409;
    my $num_warn = 0;
    my $num_crit = 0;
    my @crits;
    my @warns;
LOG_LINE:
    foreach my $line ( split '\n', $output ) {
        ## What we're retrieving is the number of 409s per 100,000 rspcodes.
        ##  So 5% 409s would be equal to 5000 out of 100,000.
        if ( $line =~ m{^from\s+.\d+.\s+to\s+.(\d+).\s+:\s+409s/all\s+=\s+.\S+\s+;\s+running\s+avg\s+=\s+\S+\s+running\s+avg\s+\*\s+100k\s+=\s+(\d+)$}xms ) {
          $current_ts    = $1;
          $hundred_k_409 = $2;
          next LOG_LINE
              unless (defined $hundred_k_409) && (defined $current_ts);
          if ( ! defined($prev_ts) ) {
            $prev_ts = $current_ts - 14;
          }
          $step = $current_ts - $prev_ts;
          if ($step < 13 || $step > 16) {
            nagios_unknown("409-percentages-for-3it", "Bad incremental runtime for 409-watcher: [$step]");
            return;
          }
          # if ANY of the last minute's 409 counts are greater than thresholds,
          #  then alarm.
          $num_hundred_k_409 = getnum( $hundred_k_409 );
          my $pctage = sprintf("%3.4f", ($num_hundred_k_409/1000));
          if ($num_hundred_k_409 >= $crit_thresh) {
            $num_crit++;
            push @crits, $pctage;
          }
          if ($num_hundred_k_409 >= $warn_thresh) {
            $num_warn++;
            push @warns, $pctage;
          }
        }
        $prev_ts = $current_ts;
    }
    if ($num_crit > 0) {
        my $pctage = pop @crits;
        nagios_critical("409-percentages-for-3it", "${three_it_oamp_host}; ${pctage}%");
        return;
    }
    if ($num_warn > 0) {
        my $pctage = pop @warns;
        nagios_warning("409-percentages-for-3it", "${three_it_oamp_host}; ${pctage}%");
        return;
    }
    if ( ! defined($current_ts) || ! defined($num_hundred_k_409) ) {
        nagios_unknown("409-percentages-for-3it", "Can't find 409 data from 3it OAMP. Is [${three_it_oamp_host}:/home/novarra/bin/rspcode-monitor/409-watcher] running?");
        return;
    }
    my $ok_pctage = sprintf("%3.4f", ($num_hundred_k_409/1000));
    my $datestr = localtime($current_ts);
    nagios_ok ("409-percentages-for-3it", "409 % ok: ${ok_pctage}%","${three_it_oamp_host}; ${ok_pctage}%");
    return;
}

sub check_rrd_processes($) {
    my $host = shift;
    my $output = check_via_nagios_ssh( "ps auxww | egrep rrd", $host );
    use vars qw( $junk $found );
    $found = 0;
PS_LINE:
    foreach $junk ( split /\n/, $output ) {
      if ( $junk =~ m{/generate-rrds-from-content-unified} ) {
        $found++;
        next PS_LINE;
      }
      if ( $junk =~ m{/generate-rrds-from-unified} ) {
        $found++;
        next PS_LINE;
      }
      if ( $junk =~ m{/rrd-graph-and-upload} ) {
        $found++;
        next PS_LINE;
      }
    }
    if ($found != 3) {
      nagios_critical ("rrd-processes", "${host};${found}","");
    }
    nagios_ok ("rrd-processes", "${host};${found}","");
}

###########################################################
# check df on remote host, exit with correct nagios output on STDOUT and
# with correct error code
#  @param $hostname
#  @exit with single-line string of results to STDOUT, e.g.:
#    EXAMPLE GOES HERE
#  Standard format is at
#    http://nagiosplug.sourceforge.net/developer-guidelines.html#PLUGOUTPUT
###########################################################
sub check_df {
    eval { validate_thresholds(">="); }; if ($@) { nagios_unknown("validate_thresholds","$@"); }
    my $hostname = shift;
    my $output = check_via_nagios_ssh( "df", $hostname );
    my (@rows, @vals, $line, @nag_problems, $nag_summary, $nag_details);
    my ($warn_msg, $crit_msg);
    $nag_details="";
    $nag_summary="";

    my $df_Filesystem="";
    # loop thru df output from remote host
    DF_LINES:
    foreach $line (split "\n", $output) {
        my ($partition, $df_1K_blocks, $df_Used, $df_Available, $df_Use_Percentage, $df_Mounted_on);
        ($partition, $df_1K_blocks, $df_Used, $df_Available, $df_Use_Percentage, $df_Mounted_on) = split /\s+/, $line;
        my ($pctage, $junk) = split /%/, $df_Use_Percentage;
        my $detail = "pct_" . $df_Mounted_on . "=" . $pctage . "%;" . $warn_thresh . ";" . $crit_thresh . ";;";
        $nag_details .= ( "" eq $nag_details ? $detail : (" " . $detail) );
        my $summary = $df_Filesystem . ":" . $df_Mounted_on . ":" . $df_Use_Percentage;
        $nag_summary .= ( "" eq $nag_summary ? $summary : (" " . $summary) );
	my $num_pctage = getnum( $pctage );
        if ($num_pctage > $crit_thresh) {
            $crit_msg = $nag_details;
            last DF_LINES;      # we're done if critical
        } else {
            if ($num_pctage > $warn_thresh) {
                $warn_msg = $nag_details;
            }
        }
    }
    if ( defined($crit_msg) ) {
        nagios_critical( "check_df", "host [$hostname]: " . $crit_msg, $nag_details );
    }
    if ( defined($warn_msg) ) {
        nagios_warning( "check_df", "host [$hostname]: " . $warn_msg, $nag_details );
    }
    nagios_ok( "check_df", "host [$hostname]: " . $nag_summary, $nag_details );
}

#### [nagios@LABITA-HP-47 libexec]$ ./check_load -w 0.7,1.0,2 -c 0.8,1.1,2.2
#### OK - load average: 0.22, 0.26, 0.16|load1=0.220;0.700;0.800;0; load5=0.260;1.000;1.100;0; load15=0.160;2.000;2.200;0;
#### [nagios@LABITA-HP-47 libexec]$
sub check_load {
  eval { validate_thresholds(">="); }; if ($@) { nagios_unknown("validate_thresholds","$@"); }
  my $hostname = shift;
  my $remote_data = check_via_nagios_ssh( "uptime", $hostname );
  chomp $remote_data;
  nagios_unknown_terse( "host [$hostname] - bad remote data: [$remote_data]" )
    unless $remote_data =~ /load average: (\S{4}), (\S{4}), (\S{4})/;
  my $load1 = getnum($1);
  my $load5 = getnum($2);
  my $load15 = getnum($3);
  my $lhs = sprintf("load average: %1.2f, %1.2f, %1.2f",$load1,$load5,$load15);
  my $perfdata = sprintf("load1=%1.3f;%1.3f;%1.3f;0; load5=%1.3f;%1.3f;%1.3f;0; load15=%1.3f;%1.3f;%1.3f;0;",
                          $load1,$warn_thresholds[0],$crit_thresholds[0],
                          $load5,$warn_thresholds[1],$crit_thresholds[1],
                          $load15,$warn_thresholds[2],$crit_thresholds[2] );
  my $output = $lhs . "|" . $perfdata;
  if ($load1 >=  $crit_thresholds[0]) { nagios_critical_terse($lhs,$perfdata); }
  if ($load5 >=  $crit_thresholds[1]) { nagios_critical_terse($lhs,$perfdata); }
  if ($load15 >= $crit_thresholds[2]) { nagios_critical_terse($lhs,$perfdata); }
  if ($load1 >=  $warn_thresholds[0]) { nagios_warning_terse($lhs,$perfdata); }
  if ($load5 >=  $warn_thresholds[1]) { nagios_warning_terse($lhs,$perfdata); }
  if ($load15 >= $warn_thresholds[2]) { nagios_warning_terse($lhs,$perfdata); }
  nagios_ok_terse($lhs,$perfdata);
}

####
#### Monitor for stuck cores by performing linear regression
####   on scatter plot of TPS (y-axis) vs CPU (x-axis). x-intercept should
####   be in single digits (5%-10% cpu).
####
####   Requirements/dependencies:
####   - apla (aca-perf-load-averager) must be running on remote host and
####     logging to /var/log/novarra/aca-perf-load-averager.log on that
####     remote host
####   - passwordless-ssh nagios acct must be on remote host
####   - GNU Scientific Library must be installed on nagios box
####   - "apla-from-stdio" must be installed on nagios box
####
#### swhitney, 24 sep 2008
####
sub apla_tps_cpu_linear_regression($$$) {
  validate_thresholds(">=");
  use Fcntl;
  use POSIX;
  my $ME = "STUCK_CORE_MON";
  my $APLA_EXE = "/usr/local/src/apla/apla-from-stdio";
  my $aca    = shift;
  my $dp_window = shift;   # which sample? instant, lo, mid, hi
  my $N      = shift;   # window, in minutes
  if ( ($dp_window ne "0")
       && ($dp_window ne "1")
       && ($dp_window ne "5")
       && ($dp_window ne "15") ) {
    nagios_unknown($ME,"Bad dp_window:[$dp_window], must be [0,1,5,15]");
  }
  if (($N < 1) || ($N > 60*24)) {
    nagios_unknown($ME,"Bad N:[$N], must be in range 1 min - 1 day");
  }
  if ( ! -f $APLA_EXE ) {
    nagios_unknown($ME,"Can't find apla executable [$APLA_EXE]");
  }
  if ( ! -x $APLA_EXE ) {
    nagios_unknown($ME,"apla executable [$APLA_EXE] isn't executable");
  }
  use vars qw( $N_five_secs $tail_out @lines $there_epoch $first_line );
  use vars qw( $apla_in_file $apla_err_file );
  $N_five_secs = $N * 12;
  $tail_out = check_via_nagios_ssh( 'date +%s', $aca );
  my $here_epoch = time;
  ($there_epoch, @lines) = split '\n', $tail_out;
  my $time_diff = $here_epoch - $there_epoch;
  if ($time_diff < 0) { $time_diff = -1 * $time_diff ; }
  if ($time_diff > 120) {
    nagios_unknown($ME,"Wallclock time difference is greater than one minute");
  }
  $tail_out = check_via_nagios_ssh( "tail -${N_five_secs} /var/log/novarra/aca-perf-load-averager.log", $aca );
  @lines = split '\n', $tail_out;
  my ($tstamp,
        $junk,$cpu_1,$cpu_5,$cpu_15,
        $ses_0,$ses_1,$ses_5,$ses_15,
        $tps_0,$tps_1,$tps_5,$tps_15 )
      = split '\s+', $lines[$#lines-1];
  $time_diff = $here_epoch - $tstamp;
  if ($time_diff < 0) { $time_diff = -1 * $time_diff ; }
  if ($time_diff > 60) {
    nagios_unknown($ME,"APLA log time stale, > 60 seconds: here=[${here_epoch}],there=[${tstamp}].");
  }
  do {
    $apla_in_file = tmpnam();
  } until sysopen(APLA_IN_FH, $apla_in_file, O_RDWR|O_CREAT|O_EXCL, 0666);
  print APLA_IN_FH $tail_out;
  if ( ! close APLA_IN_FH ) {
    nagios_unknown($ME,"Couldn't close tmp file [$apla_in_file]: $!");
  }
  $apla_err_file = tmpnam();
  my $seconds = $N_five_secs * 5;
  my $apla_cmd = qq{ ${APLA_EXE} ${seconds} ${dp_window} < ${apla_in_file} 2> ${apla_err_file} };
  my $apla_out = `${apla_cmd}`;
  @lines = split '\n', $apla_out;
  if (($#lines > 1) || ($#lines < 0)) {
    nagios_unknown($ME,"Bad output from APLA GSL cmd: [${apla_cmd}]. Output=[$apla_out];\$#lines=[$#lines]\n");
  }
  my $numstr = $lines[$#lines];
  # output format:
  # 1221216964 :  best fit: CPU = 15.2871 + -1.94853 TPS, cov[00]=[1.74322],cov[01](=cov[10])=[-0.475172],cov[11]=[0.133735], chi^2 = 7074.43
  $numstr =~ s/^\d+ :\s+best fit: CPU = (\S+) +.+$/$1/;
  my $intercept = getnum($numstr);
  if ($intercept > $crit_thresh) { nagios_critical($ME,"intercept=[$intercept] > [$crit_thresh]",$lines[$#lines]); }
  if ($intercept > $warn_thresh) { nagios_warning ($ME,"intercept=[$intercept] > [$warn_thresh]",$lines[$#lines]); }
  nagios_ok ($ME,"intercept=[$intercept]",$lines[$#lines]);
}

#### SWAP OK - 100% free (1983 MB out of 1983 MB) |swap=1983MB;0;0;0;1983
sub check_swap {
  eval { validate_thresholds("<="); }; if ($@) { nagios_unknown("validate_thresholds","$@"); }
  my $hostname = shift;
  my $remote_data = check_via_nagios_ssh( "free -m", $hostname );
  chomp $remote_data;
  nagios_unknown( "SWAP", "host [$hostname] - bad remote data: [$remote_data]" )
   unless $remote_data =~ /Swap:\s+(\d+)\s+(\d+)\s+(\d+)/;
  my $total = getnum($1);
  my $used  = getnum($2);
  my $free  = getnum($3);
  my $free_pct = ($free / $total) * 100;
  my $lhs = sprintf("%d%% free (%d MB out of %d MB)",$free_pct,$free,$total);
  my $perfdata = sprintf("swap=%d;0;0;0;%d",$free,$total);
  if ($free_pct < $crit_thresh) { nagios_critical("SWAP",$lhs, $perfdata); }
  if ($free_pct < $warn_thresh) {  nagios_warning("SWAP",$lhs, $perfdata); }
  nagios_ok("SWAP",$lhs, $perfdata);
}

# This just parses multiple warn or crit thresholds, separated by ","
# TODO: parse the full set of threshold options:
#   http://nagiosplug.sourceforge.net/developer-guidelines.html#THRESHOLDFORMAT
sub parse_threshold {
    my $input_str = shift;
    my $aref = shift;
    if ( ! $input_str =~ /,/ ) {
        $aref->[0] = $input_str;
        return;
    }
    my @inputs = split(/,/, $input_str);
    for (my $i=0; $i<=$#inputs; $i++) {
        my $num;
        eval { $num = getnum($inputs[$i]); };
        if ($@) { die "Non-numeric threshold [$inputs[$i]] : $@" ; }
        $aref->[$i] = $num;
    }
    return;
}

sub validate_thresholds {
  my $warn_vs_crit = shift;
  ## swhitney - FIXME - how to do this cleanly in perl?
  if ( ! defined($warn_vs_crit) ) {
    die "Undefined comparison operator";
  }
  if ( (">=" ne $warn_vs_crit) && ("<=" ne $warn_vs_crit) ) {
    die "Unknown comparison operator: [$warn_vs_crit]";
  }
  for (my $key=0; $key <= $#warn_thresholds; $key++) {
    if (!defined($crit_thresholds[$key])) {
      die "State mismatch: warn_thresholds[$key] exists, but crit_thresholds[$key] doesn't.";
    }
    if ( (">=" eq $warn_vs_crit) && ($warn_thresholds[$key] >= $crit_thresholds[$key]) ) {
      die "Invalid args: warn_thresholds[$key]=[$warn_thresholds[$key]] >= crit_thresholds[$key]=[$crit_thresholds[$key]]";
    }
    if ( ("<=" eq $warn_vs_crit) && ($warn_thresholds[$key] <= $crit_thresholds[$key]) ) {
      die "Invalid args: warn_thresholds[$key]=[$warn_thresholds[$key]] <= crit_thresholds[$key]=[$crit_thresholds[$key]]";
    }
  }
  for (my $key=0; $key <= $#crit_thresholds; $key++) {
    if (!defined($warn_thresholds[$key])) {
      die "State mismatch: crit_thresholds[$key] exists, but warn_thresholds[$key] doesn't.";
    }
  }
  if (defined($warn_thresholds[0]) && defined($crit_thresholds[0])) {
    $warn_thresh = $warn_thresholds[0];
    $crit_thresh = $crit_thresholds[0];
  }
  return;
}
        
###########################################################
# parse cmd line
###########################################################
getopts('VhH:w:c:o:T:t:A:D:');
if ($opt_V) { print "${BASENAME} ${VERSION}\n"; exit 0; }
if ($opt_h) { print "${USAGE}\n";      exit 0; }
my $timeout = 10;
# cref http://nagiosplug.sourceforge.net/developer-guidelines.html#RUNTIME
if ($opt_t) {
    nagios_unknown "$0", "Bad timeout [$opt_t]\n$USAGE"
      unless $timeout = getnum $opt_t;
    nagios_unknown "$0","timeout [$opt_t] s/be > 0\n$USAGE"
      unless $timeout > 0;
}
if ( defined $opt_o && ("2" eq $opt_o || "3" eq $opt_o) ) {
  #no thresholds for o2 (rrd), so dummy them out
  $opt_c = -1;
  $opt_w = -2;
}
nagios_unknown "$0",         "Missing host param\n$USAGE" unless $opt_H;
nagios_unknown "$0",  "Missing warning threshold\n$USAGE" unless $opt_w;
parse_threshold($opt_w, \@warn_thresholds);
nagios_unknown "$0", "Missing critical threshold\n$USAGE" unless $opt_c;
parse_threshold($opt_c, \@crit_thresholds);
nagios_unknown "$0",          "Missing -o option\n$USAGE" unless $opt_o;
nagios_unknown "$0",          "Missing -o option\n$USAGE" unless $opt_o;
    
("1" eq $opt_o) && check_df( $opt_H );
("2" eq $opt_o) && check_rrd_hw_failures( $opt_H, $opt_T );
("3" eq $opt_o) && check_rrd_processes( $opt_H );
("4" eq $opt_o) && check_409_monitor_on_3it();
("5" eq $opt_o) && check_load( $opt_H );
("6" eq $opt_o) && check_swap( $opt_H );
("666" eq $opt_o) && apla( $opt_H,"cpu","ALL",5 );
("667" eq $opt_o) && apla( $opt_H,"ses","ALL",5 );
("668" eq $opt_o) && apla( $opt_H,"tps","ALL",5 );
("2112" eq $opt_o) && apla_tps_lo_cpu_hi( $opt_H,"tps","ALL",5 );
if ("u812" eq $opt_o) {
  $opt_A = "0"
    unless defined($opt_A);
  $opt_D = "30"
    unless defined($opt_D);
  apla_tps_cpu_linear_regression( $opt_H, $opt_A, $opt_D );
}

nagios_critical "Unknown -o option [$opt_o]\n$USAGE" ;
